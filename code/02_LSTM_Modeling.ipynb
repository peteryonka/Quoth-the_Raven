{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: LSTM Model Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll look in detail at the steps used to build one of our LSTM models for evaluation.\n",
    "\n",
    "Due to the size and resource needs of the models, the actual models will be run on an Amazon Web Services Elastic Computing instance allowing us to build and train several versions of the model while decreasing the time to complete one epoch from ~1 hour to xxxxx (my personal computer does not have a GPU). Please refer to the AWS script folder (and modify as needed).\n",
    "\n",
    "Also, for sake of clarity, the functions referenced in each step are included in this notebook to make the process easier to follow. The functions are separated into in the AWS script to streamline the creation process.\n",
    "\n",
    "* [Section A: Load File Containing the Generated Sequences From Our Corpus](#load)\n",
    "* [Section B: Use `Tokenizer` from the Keras API to Encode our Sequences](#tokenize)\n",
    "* [Section C: Preparing Data for Training (Defining X and y)](#xandy)\n",
    "* [Section D: Define, Fit, and Save LSTM Model With Embedding Layer](#model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from contextlib import redirect_stdout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# setting a random seed for reproducibility\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"load\"></a>Section A: Load in File Containing the Generated Sequences From Our Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(path_and_filename):\n",
    "    sequence_data = open(path_and_filename).read()\n",
    "    sequences = sequence_data.split('\\n')\n",
    "    \n",
    "    words_in_seq = len(sequences[0].split()) - 1\n",
    "    \n",
    "    print(f'{len(sequences)} sequences have been loaded.')\n",
    "    print(f'Each sequence has {words_in_seq} word token(s) plus an output token.')\n",
    "    return sequences, words_in_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480044 sequences have been loaded.\n",
      "Each sequence has 25 word token(s) plus an output token.\n"
     ]
    }
   ],
   "source": [
    "sequence_list, seq_length = load_sequences('../data/Poe_NLG/03_Text_files_for_models/cleaned_poe_tot_seq_len_26.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Upon my return to the United States a few months ago , after the extraordinary series of adventure in the South Seas and elsewhere , of',\n",
       " 'my return to the United States a few months ago , after the extraordinary series of adventure in the South Seas and elsewhere , of which',\n",
       " 'return to the United States a few months ago , after the extraordinary series of adventure in the South Seas and elsewhere , of which an',\n",
       " 'to the United States a few months ago , after the extraordinary series of adventure in the South Seas and elsewhere , of which an account',\n",
       " 'the United States a few months ago , after the extraordinary series of adventure in the South Seas and elsewhere , of which an account is']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"tokenize\"></a>Section B: Use `Tokenizer` from the Keras API to Encode our Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map words to integers for each sequence\n",
    "def tokenize_words(sequence_list, filter_string='', lower_case=True):\n",
    "     \n",
    "    tokenizer = Tokenizer(filters=filter_string, lower=lower_case)\n",
    "    \n",
    "    tokenizer.fit_on_texts(sequence_list)\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(sequence_list)\n",
    "    \n",
    "    vocabulary_size = len(tokenizer.word_index) \n",
    "    \n",
    "    print(f'Sequences have been tokenized using Keras API Tokenizer.')\n",
    "    print(f'Vocabulary size is {vocabulary_size}')\n",
    "    \n",
    "    return tokenizer, sequences, vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences have been tokenized using Keras API Tokenizer.\n",
      "Vocabulary size is 22466\n"
     ]
    }
   ],
   "source": [
    "tokenizer, sequences, vocab_size = tokenize_words(sequence_list, filter_string='', lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"xandy\"></a>Section C: Preparing Data for Training (Defining X and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_and_output_sequences(sequences, vocab_size):\n",
    "    sequences = np.array(sequences)\n",
    "    X, y = sequences[:,:-1], sequences[:, -1]\n",
    "    y = utils.to_categorical(y, num_classes = vocab_size+1) # plus one required due to 0-offset of array\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_and_output_sequences(sequences, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480044, 25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480044, 22467)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='model'></a>Section D: Define, Fit, and Save LSTM Model With Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LSTM_model(vocab_size, seq_length, layer_size=256, embedding=True, embedding_vector_space=128, dropout=True, dropout_rate=0.2):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    if embedding:\n",
    "        model.add(Embedding(input_dim=vocab_size+1, output_dim=embedding_vector_space, input_length=seq_length))\n",
    "        model.add(LSTM(layer_size, return_sequences=True))\n",
    "    else:\n",
    "        model.add(LSTM(layer_size, input_shape = (seq_length, vocab_size+1), return_sequences=True))\n",
    "    \n",
    "    if dropout:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(LSTM(layer_size))\n",
    "    \n",
    "    if dropout:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(layer_size, activation='relu'))\n",
    "\n",
    "    model.add(Dense(vocab_size+1, activation='softmax'))\n",
    "    \n",
    "    print(f\"Model has been created.\\n\\nHere's a summary:\")\n",
    "    print(f'----------------------')\n",
    "    print(model.summary())\n",
    "    \n",
    "    model_name = f'{seq_length}_seqlen_LSTM_model_'\n",
    "    \n",
    "    \n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been created.\n",
      "\n",
      "Here's a summary:\n",
      "\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 128)           2875776   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 25, 512)           1312768   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22467)             11525571  \n",
      "=================================================================\n",
      "Total params: 18,075,971\n",
      "Trainable params: 18,075,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model, model_name = build_LSTM_model(vocab_size, seq_length, layer_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoints to save model weights (if an improvement) at each epoch\n",
    "if not os.path.isdir(f'./Model_weights/{model_name}'):\n",
    "    os.mkdir(f'./Model_weights/{model_name}')\n",
    "    \n",
    "checkpoint_path = f'./Model_weights/{model_name}/{model_name}_weights' + '-improvement-{epoch:02d}-{loss:.4f}-acc{accuracy:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callback_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll compile the model. \n",
    "\n",
    "The accuracy metric is purely as a point of reference (and personal curiosity). We don't want our accuracy to be to high (we don't want to exactly reproduce the training text), but we do want the model to learn how our defined words relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'], callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7501/7501 [==============================] - 4060s 541ms/step - loss: 6.1341 - accuracy: 0.1283\n",
      "Epoch 2/10\n",
      "7501/7501 [==============================] - 3892s 519ms/step - loss: 5.6049 - accuracy: 0.1616\n",
      "Epoch 3/10\n",
      "7501/7501 [==============================] - 3607s 481ms/step - loss: 5.3653 - accuracy: 0.1730\n",
      "Epoch 4/10\n",
      "7501/7501 [==============================] - 3819s 509ms/step - loss: 5.2711 - accuracy: 0.1758\n",
      "Epoch 5/10\n",
      "7501/7501 [==============================] - 3830s 511ms/step - loss: 5.1081 - accuracy: 0.1841\n",
      "Epoch 6/10\n",
      "3475/7501 [============>.................] - ETA: 34:34 - loss: 4.9883 - accuracy: 0.1905"
     ]
    }
   ],
   "source": [
    "model.fit(X,y, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and model summary\n",
    "if not os.path.isdir(f'./Models/{model_name}'):\n",
    "    os.mkdir(f'./Models/{model_name}')\n",
    "\n",
    "with open(f'./Models/{model_name}/{model_name}_summary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()\n",
    "\n",
    "model.save(f'./Models/{model_name}/{model_name}_word_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
