{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: LSTM Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pickle import load\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# no random seed included as it doesn't allow for random generation of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the selected sequence data generated during our data preparation\n",
    "def load_sequences(path_and_filename):\n",
    "    sequence_data = open(path_and_filename).read()\n",
    "    sequences = sequence_data.split('\\n')\n",
    "    \n",
    "    words_in_seq = len(sequences[0].split()) - 1\n",
    "    \n",
    "    print(f'{len(sequences)} sequences have been loaded.')\n",
    "    print(f'Each sequence has {words_in_seq} word token(s) plus an output token.')\n",
    "    return sequences, words_in_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the above function to reload our sequences into this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480044 sequences have been loaded.\n",
      "Each sequence has 25 word token(s) plus an output token.\n"
     ]
    }
   ],
   "source": [
    "sequence_list, seq_length = \\\n",
    "load_sequences('../../data/Poe_NLG/03_Text_files_for_models/cleaned_poe_tot_seq_len_26.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in our saved model that we downloaded from AWS and placed in our repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading our selected model from the modeling step (downloaded from AWS)\n",
    "model = load_model('./Models/Models_25_seqlen_LSTM_model/25_seqlen_LSTM_model_word_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll reload our saved tokenizer to reuse for language generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer we created in the previous notebook\n",
    "tokenizer = load(open('./Models/Models_25_seqlen_LSTM_model/25_seqlen_LSTM_model_tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating text from our model based on the provided seed text\n",
    "def generate_text(model, tokenizer, seq_length, seed_text, num_new_words):\n",
    "    \n",
    "    # create a variable to hold our generated words\n",
    "    result = []\n",
    "    \n",
    "    # set the input text as the seed text to start -- this input text will change based on the new words added\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # we'll loop through next word predictions based on the number of words requested in the function call\n",
    "    for _ in range(num_new_words):\n",
    "        \n",
    "        # convert input text to integer\n",
    "        encoded = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # we'll adjust the tokenized data to make sure it has the correct shape for the model \n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        \n",
    "        # the model will predict the next word generating a probability for each word in vocab\n",
    "        predictions = model.predict(encoded)\n",
    "        \n",
    "        # we'll use the predictions as weights and make a random choice based on those weights\n",
    "        # future interations could add a temperature adjustment here instead\n",
    "        pred = np.random.choice(len(predictions[0]), p=predictions[0])\n",
    "        \n",
    "        # we'll instantiate/reset the output word \n",
    "        output_word = ''\n",
    "        \n",
    "        # we'll look for the value associated with the index of the predicted word and return it when it's found\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == pred:\n",
    "                output_word = word\n",
    "                break\n",
    "        \n",
    "        # we'll append the new word to our input string for the next interation\n",
    "        input_text += ' ' + output_word\n",
    "        \n",
    "        # we'll add the output world to result word list\n",
    "        result.append(output_word)\n",
    "    \n",
    "    # finally, when we finish generating the requested number of words, we send back the results\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed text:\n",
      "A woman stands by a large \n",
      "\n",
      "\n",
      "bird - eyed Frinchman called horrors hold gently with a funnel vault and then faintly steadily with an instant . They never succeed in getting out of blood , extending against the southern gate of her chair , and from one astronomers which ever struck the first chasm . They...\n",
      "\n",
      "END OF GENERATED TEXT\n",
      "\n",
      "------------\n",
      "\n",
      "Seed text:\n",
      "A family looks over the side of a \n",
      "\n",
      "\n",
      "seat , forming his associates picked up with the bees and No - sounding scarf . We therefore gave a bill of events to dancing , bearing a hideous many bottles of thoughts . \" But yet go -- from comparison with the wings of Mr . Seabright Ellison ....\n",
      "\n",
      "END OF GENERATED TEXT\n",
      "\n",
      "------------\n",
      "\n",
      "Seed text:\n",
      "The wind howls across the \n",
      "\n",
      "\n",
      "apartment . And the shadow around , although its color sprang away together , almost intoxicated as the eye did been drowned . A great rush took fat , and they lay prostrate in as operated to assure him as yet to follow . The case of her sail seems...\n",
      "\n",
      "END OF GENERATED TEXT\n",
      "\n",
      "------------\n",
      "\n",
      "Seed text:\n",
      "The sky bleeds \n",
      "\n",
      "\n",
      "-- vague , respectable gxxse , her whom . Her set with silver lace , lay by forces among the house -- then even forward the clock , but adjusting their address , in tears in the season , than a threat of nature -- a child ; but no...\n",
      "\n",
      "END OF GENERATED TEXT\n",
      "\n",
      "------------\n",
      "\n",
      "Seed text:\n",
      "The meaning of life is\n",
      "\n",
      "\n",
      "thus French came erect forever in stature and device . Suddenly he floated close at the corners of the angels , which pressed upon the street with Peters , and giving this terrible position very near into way by regard to the mesmeric influence , it must rise to commence...\n",
      "\n",
      "END OF GENERATED TEXT\n",
      "\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating some results based on a list of seed texts\n",
    "seed_text = ['A woman stands by a large ', 'A family looks over the side of a ', 'The wind howls across the ', 'The sky bleeds ', 'The meaning of life is']\n",
    "for seed in seed_text:\n",
    "    generated = generate_text(model, tokenizer, seq_length, seed, 50)\n",
    "    print(f'Seed text:\\n{seed}\\n')\n",
    "    print(f'\\n{generated}...\\n')\n",
    "    print(f'END OF GENERATED TEXT\\n')\n",
    "    print(f'------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
