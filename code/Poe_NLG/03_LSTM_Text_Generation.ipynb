{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: LSTM Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pickle import load\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(path_and_filename):\n",
    "    sequence_data = open(path_and_filename).read()\n",
    "    sequences = sequence_data.split('\\n')\n",
    "    \n",
    "    words_in_seq = len(sequences[0].split()) - 1\n",
    "    \n",
    "    print(f'{len(sequences)} sequences have been loaded.')\n",
    "    print(f'Each sequence has {words_in_seq} word token(s) plus an output token.')\n",
    "    return sequences, words_in_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480044 sequences have been loaded.\n",
      "Each sequence has 25 word token(s) plus an output token.\n"
     ]
    }
   ],
   "source": [
    "sequence_list, seq_length = \\\n",
    "load_sequences('../data/Poe_NLG/03_Text_files_for_models/cleaned_poe_tot_seq_len_26.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./Models/Models_25_seqlen_LSTM_model/25_seqlen_LSTM_model_word_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(open('./Models/Models_25_seqlen_LSTM_model/25_seqlen_LSTM_model_tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = sequence_list[np.random.randint(0, len(sequence_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most remote degree , connected with my family . But assuredly if we had been brothers we must have been twins ; for , after\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_length, seed_text, num_new_words):\n",
    "    result = []\n",
    "    input_text = seed_text\n",
    "    for _ in range(num_new_words):\n",
    "        encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        predictions = model.predict(encoded)\n",
    "#         predictions = (model.predict(encoded) > 0.5).astype(\"int32\")\n",
    "        pred = np.random.choice(len(predictions[0]), p=predictions[0])\n",
    "        # model.predict_classes(encoded, verbose=0)\n",
    "        output_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == pred:\n",
    "                output_word = word\n",
    "                break\n",
    "        input_text += ' ' + output_word\n",
    "        result.append(output_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "others further north north fall another five my room going numerous going mere total certain personal human birth what knowing evident frequent none giving occasion others eight fifteen its evident every anything those their certain them those Augustus cutting late lying cutting its cover sail other several drawing accident certain\n"
     ]
    }
   ],
   "source": [
    "new_stuff = generate_text(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(new_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most remote degree , connected with my family . But assuredly if we had been brothers we must have been twins ; for , after\n",
      "\n",
      "others further north north fall another five my room going numerous going mere total certain personal human birth what knowing evident frequent none giving occasion others eight fifteen its evident every anything those their certain them those Augustus cutting late lying cutting its cover sail other several drawing accident certain\n"
     ]
    }
   ],
   "source": [
    "print(seed_text + '\\n')\n",
    "print(new_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
