{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05:_GPT-2_Text_Generation_With_gpt-2-simple",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  05 GPT-2 Model Text Generation With gpt-2-simple (Colab notebook)\n",
        "\n",
        "*Note: This notebook is an edited version the original Google Colab notebook by [Max Woolf](http://minimaxir.com), creator of the `gpt-2-simple` wrapper for OpenAI's GPT-2. Since this notebook provided an easy workflow directly from the creator as well as Colab's access to a free GPU, I decided to maximize efficiency and usability by using it as the base rather than building a new one.*\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [Max's GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read his [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for a link to the original version and more information how to use this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDYWoOsy0byt"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Please note: this wrapper uses TensorFlow v1.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae51d976-250d-48d3-d85d-596853c24c23"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "We'll verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa8525fa-2824-4453-bfa0-17c542f95ce8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan 27 10:36:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "Next, we'll connect to our Google Drive by running the cell below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28cdfd70-2e68-4501-bb99-9d7bb6045109"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.tar` checkpoint file from your Google Drive into the Colaboratory VM. The filename will be in the form of `checkpoint_{run_name}.tar`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61542bd8-9d7e-4801-e6b5-9f485703497e"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-10000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "**Some great notes from Max:**\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N"
      },
      "source": [
        "def generate_examples(sess, length=150, temperature=0.7, \n",
        "                      top_p =0.0, top_k=0.0, seed = None, \n",
        "                      prefix='', nsamples=5, batch_size=5):\n",
        "  result = gpt2.generate(sess,\n",
        "                length=length,\n",
        "                temperature=temperature,\n",
        "                prefix=prefix,\n",
        "                seed=seed,\n",
        "                top_p = top_p,\n",
        "                nsamples=nsamples,\n",
        "                batch_size=batch_size\n",
        "                )\n",
        "  return result"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSsHeZQNPA-I"
      },
      "source": [
        "# function to look at generative text given a passed list of temperatures\n",
        "def generate_examples_by_temp(temperture_list, sess, prefix='', nsamples=1, batch_size=1):\n",
        "  temperatures = temperature_list\n",
        "  result = ''\n",
        "  for temperature in temperatures:\n",
        "    print(f'\\nResults for temperature of {temperature}\\n')\n",
        "    generate_examples(sess=sess, temperature=temperature, prefix=prefix, nsamples=nsamples, batch_size=batch_size)\n",
        "    print(f'\\nEnd of Samples\\n')\n",
        "    print(f'*--*--*--*--*--*--*--*--*--*--*--*--*--*--')\n",
        "  return 'END OF TEMPERATURE GENERATED EXAMPLES'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNSCASG-YRFQ"
      },
      "source": [
        "# temperature list to look at resultant outputs\n",
        "temperature_list = [0.2, 0.5, 0.7, 1.0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vdLjHkynTDD2",
        "outputId": "5408a48e-3886-4742-aa8f-af2d037010bf"
      },
      "source": [
        "# setting the lead in prefix as an incomplete sample caption\n",
        "sample_caption = 'A young couple stands on'\n",
        "\n",
        "# generating generative examples by temperature for the sample caption\n",
        "generate_examples_by_temp(temperature_list, sess, prefix=sample_caption)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results for temperature of 0.2\n",
            "\n",
            "A young couple stands on a balcony looking at a window. At\n",
            "      their right hand is a table, and on their left a table,\n",
            "      alternately of silk and papyrus. Here they areas well\n",
            "      aware of the great beauty of their salon, but from the\n",
            "      corner of the room they perceive a vast number of\n",
            "      oriels, minarets, and pinnacles, allured by the rich\n",
            "      draperies and costly lamps of the owner. Some few words\n",
            "      are said between the tressels of the company, but the\n",
            "      conversation is\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.5\n",
            "\n",
            "A young couple stands on a balcony looking at a view of the river. At a corner of the\n",
            "      canal steps steps lead into a side street. On the sidewalk is found a\n",
            "      little building, bearing a large bell. It is opened and closed\n",
            "      frequently. It is noticed that it is not much used at night.\n",
            "\n",
            "      The ground of the street is irregularly shaped. It is a late\n",
            "      addition to the scene, and has been painted over. The\n",
            "      main building is the first story. From the back door of\n",
            "      this story leads to the second story. In the front parter\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.7\n",
            "\n",
            "A young couple stands on a bridge over the river,\n",
            "      hearing the sound of a watersong. They approach it,\n",
            "      stoop, and approach it slowly. They listen to its\n",
            "      reverberation—to its echo—to its reflection. They are not\n",
            "      able to decide how or why it is. They are even doubtful about\n",
            "      its being a bird of paradise. Its echo is heard\n",
            "      by the man-animals with the thread of their step. The\n",
            "      watersong is their wail, and their wail is the din of\n",
            "      watersonged heaven\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 1.0\n",
            "\n",
            "A young couple stands on a hillside—one of them\n",
            "      is occupied in cutting away the\n",
            "      fascinator—and the more intimate of the pair is on the\n",
            "      point of recommencing the service. Anticipate your\n",
            "      sensations when the fire department approaches, and make them\n",
            "      as comfortable as these. In the meantime, strap on your\n",
            "      clothes and go off as speedily as possible. Once upon your\n",
            "      feet, make sure you have secured your everybody in your\n",
            "      own way—that is to say, lay them in their own way—and\n",
            "  \n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'END OF TEMPERATURE GENERATED EXAMPLES'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yG3i7YiPYAJ7",
        "outputId": "60b93865-d3d5-44d4-c8ec-5192185049b6"
      },
      "source": [
        "# setting the lead in prefix as an incomplete sample caption\n",
        "sample_caption = 'A wall of bricks'\n",
        "\n",
        "# generating generative examples by temperature for the sample caption\n",
        "generate_examples_by_temp(temperature_list, sess, prefix=sample_caption)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results for temperature of 0.2\n",
            "\n",
            "A wall of bricks\n",
            "      and mortar, and a mass of loose bricks and mortar, all\n",
            "       clustered into a very large and very impenetrable\n",
            "       circle, with a long section of one of the bricks at the\n",
            "       centre. On the edge of this circle, and a few paces from the\n",
            "       centre, stood a human skeleton, posed evidently for the\n",
            "       purpose of executing some sweeping movements for the\n",
            "       safety of the surrounding world.\n",
            "\n",
            "       But, as the great shakes and jumps in the boat were\n",
            "    \n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.5\n",
            "\n",
            "A wall of bricks\n",
            "      and mortar, together with a bed of oak, lay near us.\n",
            "\n",
            "      We were nearly three hours in reaching the end of this passage,\n",
            "      when we received a yell of fire. It was a prodigious sight to behold,\n",
            "      even from the perspective of the savages. We scrambled to\n",
            "      get up our weapons, but had no difficulty in doing so, when\n",
            "      one of the men got them from the cabin, and, throwing\n",
            "      them at the head of the savages, killed them instantly. The\n",
            "      rest of the captives we\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.7\n",
            "\n",
            "A wall of bricks\n",
            "      and mortar was wedged between us and the door leading into\n",
            "      the yard; but we could see nothing of the landlord’s valet.\n",
            "\n",
            "      The dismal and horrible scene which ensued is not to be imagined.\n",
            "      The loudest groans of the servant were heard, as well as\n",
            "      many other groans, beneath the windows; and awful shrieks\n",
            "      arose at every opening, such as we had never before found\n",
            "      filled with horror from our own confinement, or from the\n",
            "      total absence of the domestic life we had assumed\n",
            "\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 1.0\n",
            "\n",
            "A wall of bricks will\n",
            "      do fine for a house.” Whatever you may think of the\n",
            "      architect of Nopolis, always prefer the work of Strabo to that of\n",
            "      Demosthenes or Aries Cole.” Visit my portfolio at www.gproboards.com.\n",
            "      Or better yet, consider the project of your own hands. What\n",
            "      emerges from your sewer, or drains into your well, may be\n",
            "      of immense benefit to your art. A radio, or an\n",
            "      air-conditioning system, with wires, would be of far\n",
            "   \n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'END OF TEMPERATURE GENERATED EXAMPLES'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U7obVnKHagmT",
        "outputId": "3648cad7-a95b-49b1-85ed-8a91235a240d"
      },
      "source": [
        "# setting the lead in prefix as an incomplete sample caption\n",
        "sample_caption = 'A man walks on the beach'\n",
        "\n",
        "# generating generative examples by temperature for the sample caption\n",
        "generate_examples_by_temp(temperature_list, sess, prefix=sample_caption)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results for temperature of 0.2\n",
            "\n",
            "A man walks on the beach.”\n",
            "\n",
            "      “And the man who sat upon the rock,” said the king, “is the\n",
            "      man who lies upon the sand.”\n",
            "\n",
            "      “And the man who lies upon the rock,” said the king, “is the\n",
            "      guardian of the shrine which is in the hills.”\n",
            "\n",
            "      “And the man who lies upon the sand,” said the king, “is the\n",
            "      son of Athelas.”\n",
            "\n",
            "      “And the man who lies upon the rock,” said\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.5\n",
            "\n",
            "A man walks on the beach.”\n",
            "\n",
            "      “Man-of-the-World!”\n",
            "\n",
            "      “What—what—what—what is it?”\n",
            "\n",
            "      “I have no idea.”\n",
            "\n",
            "      “Man-of-the-World!”\n",
            "\n",
            "      “What—what—what is it?”\n",
            "\n",
            "      “I have no idea either.”\n",
            "\n",
            "      “Man-of-the-World!”\n",
            "\n",
            "      “What—what—what is it?”\n",
            "\n",
            "     \n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.7\n",
            "\n",
            "A man walks on the beach. A boat is seen in the distance. It is\n",
            "      estimated that at least five or six of the natives are in\n",
            "      attendance. The chief executive officer of the island is on a jacuzzi,\n",
            "      with the chief wealth-lender of the tribe, and Pasquale, the\n",
            "      ninth of the nigres, who are also in attendance, as well\n",
            "      as the wife of the chief petty officer. The chief\n",
            "      beauty-talker, Pasquale, is exceedingly partial to\n",
            "      water-carriers. His nickname is Gallipago. His\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 1.0\n",
            "\n",
            "A man walks on the beach.\n",
            "    \n",
            "                                       There is no joy so profound, no palliative so exquisite,\n",
            "       no consolation so profound, as that which comes from among\n",
            "      unhallowed beats. Of late years it is perhaps more than\n",
            "      possible to be revelling in sorrow. We have seen how very\n",
            "      beautifully, with how placidly, the waste streams into the\n",
            "      channel indulge themselves, how perpetual cycles of\n",
            "  \n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'END OF TEMPERATURE GENERATED EXAMPLES'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PNNXTuH5bcZf",
        "outputId": "af3e394f-63f3-4f8d-804b-9b3422b11660"
      },
      "source": [
        "# setting the lead in prefix as an incomplete sample caption\n",
        "sample_caption = 'A woman stands by a large'\n",
        "\n",
        "# generating generative examples by temperature for the sample caption\n",
        "generate_examples_by_temp(temperature_list, sess, prefix=sample_caption)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results for temperature of 0.2\n",
            "\n",
            "A woman stands by a large\n",
            "      rock which leads into the recesses of the chasm. On the\n",
            "      side of this rock is a hole which leads directly into the\n",
            "      recesses of the morass, and forms the limit of the lowest\n",
            "      and most accessible portion of the vale. Here the sun descends\n",
            "      and disappears, and the morass is clothed in a misty and\n",
            "      heavy fog.\n",
            "\n",
            "      “The fogs and mist which encircle and enshrine the\n",
            "      morass are the foul stalks of the ash trees which grow\n",
            " \n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.5\n",
            "\n",
            "A woman stands by a large window near the top of the building. On the\n",
            "      mantelpieces are visible paintings in which are\n",
            "      recognizable but untitled birds. Some paintings are\n",
            "      represented as if they were part of the visual arts; and\n",
            "      consequently convey ideas of artesian well-being. Others\n",
            "      are simple landscapes composed with rough materials, such as\n",
            "      green leaves in the earth, or fishes in the water. The\n",
            "      sounds produced are harmony, amplitude, and uniform.\n",
            "\n",
            "      The general division of the chamber into\n",
            "      gallery and workshop, is\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.7\n",
            "\n",
            "A woman stands by a large caskET\n",
            "      which, with her feet, she had dragged from the ante-chamber\n",
            "      of the steeple, and without having opened the door,\n",
            "      is seen to be slightly tilted and defective; but,\n",
            "      upon her relighting the lamp, she again makes the\n",
            "      acquaintance of the stranger, and, taking her arm, yields her\n",
            "      hand toward him, as her back is turned toward her, when,\n",
            "      allowing her forehead to rise, she again makes the\n",
            "      acquaintance of the stranger.\n",
            "\n",
            "      The miracle\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 1.0\n",
            "\n",
            "A woman stands by a large oaken crate at the foot of the table. On the\n",
            "      lid is a generous head, shaped somewhat like an E. S.\n",
            "      The high value of the lettering on this crate will be\n",
            "      judged by the deep blue ink on its reverse, which is written,\n",
            "      in huge letters, K. But there are no acronyms, no colons,\n",
            "      no numbers, no periods, nor any other devices than\n",
            "      ‘s.’ About half of the letters are represented as _émédels,\n",
            "      so that it is quite certain\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'END OF TEMPERATURE GENERATED EXAMPLES'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ge7PlNTYbtul",
        "outputId": "100a9793-bc24-472b-9ec0-5a7b14da1bba"
      },
      "source": [
        "# setting the lead in prefix as an incomplete sample caption\n",
        "sample_caption = 'The wind howls across the'\n",
        "\n",
        "# generating generative examples by temperature for the sample caption\n",
        "generate_examples_by_temp(temperature_list, sess, prefix=sample_caption)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results for temperature of 0.2\n",
            "\n",
            "The wind howls across the heaven,\n",
            "      while the rain howls upon the earth—while the lightning\n",
            "      howls upon the trees—and while the thunder howls upon the\n",
            "      rocks—and while the lightning HOWLS upon the water-logged\n",
            "                                                                                         \n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.5\n",
            "\n",
            "The wind howls across the heaven\n",
            "      and the earth, and the stars are waxing lily-fringed.\n",
            "\n",
            "      _P._ But where are the mimes?\n",
            "\n",
            "      _V._ They are here!—here!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—mimes!—”\n",
            "\n",
            "      _P._ And where are the nooks of the serpent?\n",
            "\n",
            "      _V._ Here!—\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.7\n",
            "\n",
            "The wind howls across the heaven, and\n",
            "      the stars sparkle radiantly; but men are chained within\n",
            "      their prisons, and women are free—but the winds that\n",
            "      utter darkness hover upon the waters, and the waters that\n",
            "      crest above the rock are silent—and the thunder howls\n",
            "      amid the heaven, and the thunder howls amid the earth—but\n",
            "      the heaven is firm and unmoved, and the earth gentle and\n",
            "      unsullied, and the thunder howls amid the heaven—but the\n",
            "      heaven is firm and unparticled, and\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 1.0\n",
            "\n",
            "The wind howls across the heavens. The\n",
            "      sun goes down to rest. People stupefy in the mud. ¶ But it\n",
            "      were idle to sleep. Wheals of wrath, howling and shrieking\n",
            "      upon the graves, were the doom of all things. The seas\n",
            "      broke; the winds blew fainting. The thunder rolled; but it were\n",
            "      none of the men who rang the gates of the\n",
            "      tomb. Och hon! hon! if it were an illigant\n",
            "      corpse it would not ruffle a feather. The veins\n",
            "      were out\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'END OF TEMPERATURE GENERATED EXAMPLES'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9zWM6F_3cBaE",
        "outputId": "afa009cc-62b2-434e-e480-7236fb13aa77"
      },
      "source": [
        "# setting the lead in prefix as an incomplete sample caption\n",
        "sample_caption = 'The meaning of life is'\n",
        "\n",
        "# generating generative examples by temperature for the sample caption\n",
        "generate_examples_by_temp(temperature_list, sess, prefix=sample_caption)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results for temperature of 0.2\n",
            "\n",
            "The meaning of life is obscure. It is not the labor of the mind,\n",
            "      to which God has subjected the merely human, but of the\n",
            "      soul itself. It is the labor of the mind to know that\n",
            "      man is a machine, to which God has subjected the\n",
            "      immaterial, and to which God has no power, but to\n",
            "      which God has made known the power of life.\n",
            "\n",
            "      _P._ But you speak of _mind_ and of _consciousness_—pardon?\n",
            "\n",
            "      _V._ Yes—to which God I have no access—but in regard to\n",
            "\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.5\n",
            "\n",
            "The meaning of life is obscure. It is not the labor of the mind,\n",
            "      but the labor of the heart. It is the sympathy of the\n",
            "      soul with its fellows—with its own kind. It is the fervid, the\n",
            "      enduring, the perpetual love which blinds us to the\n",
            "      exterior world. It is the love which exists within us,\n",
            "      and animates our actions. It is the passion which\n",
            "      animates our will—and, if I may so call it, the will of\n",
            "      God.\n",
            "\n",
            "      I am not sure from what point of\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 0.7\n",
            "\n",
            "The meaning of life is obscure, and its effects are yet\n",
            "      mysterious. It is not, however, that the dim visions which cover\n",
            "      the minds of the brave fade away—they acquire a\n",
            "      brilliant lustre as the dawn of the morning—they acquire a\n",
            "      brilliancy as the diamonds of the emerald sky. Look not\n",
            "      into the abyss—into the glittering waters—into the\n",
            "      silent doubt-storms—into the smiling smiles of the\n",
            "      smiling children of the fair Alaska. These are not the\n",
            "      fancies of fancy, nor are they the\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
            "\n",
            "Results for temperature of 1.0\n",
            "\n",
            "The meaning of life is still\n",
            "      indifferently elusive. We know of nothing which can be\n",
            "      fully appreciated in its entirety, and we have, therefore, only\n",
            "      vague notions that material things exist. But it is by\n",
            "      these vague notions that our reason feels its way, and that\n",
            "      it becomes habituated to disregard what is not. It is only\n",
            "      with difficulty that we cannot receive, altogether,\n",
            "      the idea that our reason is blind.\n",
            "\n",
            "      _P._ The vague phrases are a- The vague phrases\n",
            "      are e- The idea of\n",
            "\n",
            "End of Samples\n",
            "\n",
            "*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'END OF TEMPERATURE GENERATED EXAMPLES'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, `gpt-2-simple` allows to  generate a large amount of text. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "We can rerun the cells as many times as desired and then download the text files to our local computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=250,\n",
        "                      temperature=0.7,\n",
        "                      prefix=\"\\\"My name is Poe. And you are?\\\"\",\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1516a90b-a5af-40d7-c3fc-59b594028e42"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cf5bab15-f50b-4924-9f13-5ef3670cbf43\", \"gpt2_gentext_20210125_024121.txt\", 71051)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "### LICENSE\n",
        "Since I'm extensively utilizing the framework and processes created by Max Woolf, please be aware of this licensing information related to said software.\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmJIokD27phf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}